{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Corpus(root_dir):\n",
    "    polarity_dirs = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "    polarity_dirs.sort()\n",
    "    corpus = []    \n",
    "    for polarity_dir in polarity_dirs:\n",
    "        reviews = [os.path.join(polarity_dir,f) for f in os.listdir(polarity_dir)]\n",
    "        reviews.sort()\n",
    "        for review in reviews:\n",
    "            # print(review)\n",
    "            doc_string = \"\";\n",
    "            with open(review) as rev:\n",
    "                for line in rev:\n",
    "                    doc_string = doc_string + line\n",
    "            if not corpus:\n",
    "                corpus = [doc_string]\n",
    "            else:\n",
    "                corpus.append(doc_string.replace(\"\\r\",\"\").replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"  \",\" \").split(\" \"))\n",
    "    return corpus\n",
    " \n",
    "#Create a corpus with each document having one string\n",
    "root_dir = '../preprocessedDataset'\n",
    "corpus = make_Corpus(root_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict\n",
    "\n",
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict\n",
    "\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(corpus)\n",
    "\n",
    "wordSet = set(corpus[0])\n",
    "for bow in corpus:\n",
    "    wordSet = wordSet.union(set(bow))\\\n",
    "\n",
    "wordDict = []\n",
    "for i in range(N):\n",
    "    wordDict.append(dict.fromkeys(wordSet,0))\n",
    "\n",
    "i = 0\n",
    "for bow in corpus:\n",
    "    for word in bow:\n",
    "        wordDict[i][word] += 1\n",
    "    i += 1\n",
    "\n",
    "tfBow = []\n",
    "for i in range(N):\n",
    "    tfBow.append(computeTF(wordDict[i],corpus[i]))\n",
    "\n",
    "idfs = computeIDF(wordDict)\n",
    "\n",
    "tfidfBow = []\n",
    "for i in range(N):\n",
    "    tfidfBow.append(computeTFIDF(tfBow[i],idfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.DataFrame(tfidfBow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.to_csv('../tfidf/complete.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
